% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune.dicovar.R
\name{tune.dicovar}
\alias{tune.dicovar}
\title{Tune Differential Compositional Variation Machine Learning (DiCoVarML) Models}
\usage{
tune.dicovar(
  X,
  Y,
  sample_ids,
  dv_labels,
  scale_data = TRUE,
  performRFE = FALSE,
  useRidgeWeight = FALSE,
  min_connected = FALSE,
  ensemble = c("ranger", "pls", "svmRadial", "glmnet", "rangerE"),
  max_sparsity = 0.9,
  global_imputation = FALSE,
  test.parts = c(4, 8, 12),
  k_fold = 2,
  repeats = 5,
  seed = NULL
)
}
\arguments{
\item{X}{matrix-like object with one row per sample and one column per part}

\item{Y}{vector containing response variable for each sample}

\item{sample_ids}{character vector of unique labels or names for each sample}

\item{dv_labels}{numeric vector identifying each sample as part of the discovery dataset (1) or validation dataset (2)}

\item{scale_data}{Should data be scaled to unit standard deviation?}

\item{performRFE}{Should random forest feature elimination be used when fitting DCV models?}

\item{useRidgeWeight}{Should features be scaled using ridge regression weights before DCV ensemble fitting?}

\item{min_connected}{Should logratio network be constructed with the minimum number of edges required to include a given number of parts, or should all edges with DCV scores >0 be retained?}

\item{ensemble}{character vector of models to use in the DCV ensemble, or FALSE to skip fitting ensemble models}

\item{max_sparsity}{Parts with a higher proportion of zero/missing values will be dropped before zero imputation.}

\item{global_imputation}{Should multiplicative zero imputation be performed with a constant factor across each train/test split, or should factors be calculated separately? If calculated separately, factors will be divided by 10 to give a 'safety factor' allowance for lower minimum values in the other split.}

\item{test.parts}{integer vector giving the number of parts to be tested}

\item{k_fold}{estimate model performance using k-fold cross validation}

\item{repeats}{the number of times to repeat k-fold cross validation}

\item{seed}{random seed to use for reproducible results, or NULL to generate a seed from the current value of \code{\link[base]{.Random.seed}}}
}
\value{
A list containing:\tabular{ll}{
   \code{tt_data} \tab The discovery/validation split and shared imputation factor. \cr
   \code{cv_folds} \tab The cross-validation folds used for performance estimation. \cr
   \code{test_auc} \tab The testing split ROC AUC values for each model type and target part count from inner cross-validation. \cr
   \code{inner_perf} \tab ROC AUCs on testing splits from the inner cross-validation. \cr
   \code{inner_dcv_scores} \tab Differential composition variation (DCV) scores calculated on training splits. \cr
   \code{inner_ridge_models} \tab Ridge penalized logistic regressions models fit on training splits. \cr
   \code{target_max} \tab the number of parts which yields the highest testing split AUC \cr
   \code{target_1se} \tab the smallest number of parts where testing split AUC is within 1 standard error of optimum \cr
   \tab \cr
}
}
\description{
A function that takes raw data, transforms it into the logratio space, and
tests DiCoVarML model performance using subsets of the logratios. Model fitting
will use the foreach package to take advantage of multicore processing, if
a cluster has been registered.
}
\seealso{
\code{\link[diffCompVarRcpp]{dcvScores}}
}
